# Relat√≥rio de Revis√£o - Redis, RabbitMQ, MinIO, ELK

**Data**: 2025-12-11
**Revisor**: SRE Principal
**Objetivo**: Identificar e corrigir erros nas configura√ß√µes para K3s

---

## üìä Resumo Executivo

| Componente | Status | Erros Cr√≠ticos | Erros M√©dios | Avisos |
|------------|--------|----------------|--------------|--------|
| **Redis** | ‚ö†Ô∏è NECESSITA CORRE√á√ÉO | 1 | 0 | 0 |
| **RabbitMQ** | üî¥ BLOQUEADO | 2 | 1 | 0 |
| **MinIO** | üî¥ BLOQUEADO | 3 | 1 | 0 |
| **ELK** | ‚ö™ N√ÉO ENCONTRADO | - | - | - |

---

## 1Ô∏è‚É£ REDIS - Problemas Identificados

### üî¥ ERRO CR√çTICO #1: PodAntiAffinity com Label Incorreto

**Arquivo**: `/home/k8s1/k8s/redis/22-replica-statefulset-k3s.yaml`
**Linha**: 34

**Problema**:
```yaml
podAntiAffinity:
  preferredDuringSchedulingIgnoredDuringExecution:
  - weight: 100
    podAffinityTerm:
      labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values: ["redis-replica"]  # ‚ùå ERRADO
```

**O que acontece**:
- O podAntiAffinity est√° procurando pods com label `app: redis-replica`
- Mas os pods de replica t√™m label `app: redis-cluster` (linha 8 e 21)
- **RESULTADO**: O anti-affinity NUNCA vai funcionar
- **IMPACTO**: M√∫ltiplas r√©plicas podem ser agendadas no mesmo node, violando alta disponibilidade

**Corre√ß√£o Necess√°ria**:
```yaml
matchExpressions:
- key: app
  operator: In
  values: ["redis-cluster"]  # ‚úÖ CORRETO
```

### ‚úÖ Pontos Positivos do Redis

- ‚úÖ StorageClass correto: `local-path` (K3s)
- ‚úÖ DNS correto: `.home.arpa` e `.svc.cluster.local`
- ‚úÖ Certificados TLS usando `local-ca` ClusterIssuer
- ‚úÖ ServiceLB configurado corretamente
- ‚úÖ Servi√ßos headless e LoadBalancer bem estruturados

---

## 2Ô∏è‚É£ RABBITMQ - Problemas Identificados

### üî¥ ERRO CR√çTICO #1: Ingress Configurado para NGINX

**Arquivo**: `/home/k8s1/k8s/rabbitmq/30-management-ingress.yaml`
**Linhas**: 10, 18, 11-16

**Problema**:
```yaml
annotations:
  kubernetes.io/ingress.class: nginx  # ‚ùå K3s usa Traefik!
  nginx.ingress.kubernetes.io/proxy-body-size: "0"  # ‚ùå Annotation NGINX
  nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
  nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
  nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
  nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx  # ‚ùå NGINX n√£o est√° instalado no K3s
```

**Impacto**:
- ‚õî **O Ingress N√ÉO VAI FUNCIONAR**
- O Traefik vai ignorar este Ingress
- RabbitMQ Management UI n√£o ser√° acess√≠vel externamente

**Corre√ß√£o Necess√°ria**:
- Trocar para `ingressClassName: traefik`
- Remover annotations espec√≠ficas do NGINX
- Adicionar annotations do Traefik se necess√°rio
- **OU** usar `IngressRoute` (CRD do Traefik)

### üî¥ ERRO CR√çTICO #2: Dados N√£o Persistentes

**Arquivo**: `/home/k8s1/k8s/rabbitmq/20-statefulset.yaml`
**Linhas**: 166-169, 184

**Problema**:
```yaml
volumes:
- name: data
  emptyDir: {}  # ‚ùå Dados vol√°teis!
- name: logs
  emptyDir: {}  # ‚ùå Logs vol√°teis!

# volumeClaimTemplates temporarily replaced by emptyDir for homelab
```

**Impacto**:
- üí• **PERDA DE DADOS ao reiniciar pod**
- Mensagens, filas, exchanges ser√£o perdidos
- Logs n√£o persistem entre restarts
- **INACEIT√ÅVEL PARA PRODU√á√ÉO**

**Corre√ß√£o Necess√°ria**:
```yaml
volumeClaimTemplates:
- metadata:
    name: data
  spec:
    accessModes: ["ReadWriteOnce"]
    storageClassName: local-path  # K3s
    resources:
      requests:
        storage: 10Gi
```

### ‚ö†Ô∏è AVISO: TLS Desabilitado

**Arquivo**: `/home/k8s1/k8s/rabbitmq/20-statefulset.yaml`
**Linhas**: 163-165

```yaml
volumes:
- name: ssl-certs
  emptyDir: {}  # TLS mount removido em homelab para simplificar
```

**Impacto**:
- Conex√µes AMQP e Management sem criptografia
- Senhas e dados trafegam em texto plano
- Aceit√°vel apenas para desenvolvimento local

### ‚úÖ Pontos Positivos do RabbitMQ

- ‚úÖ DNS correto: `.home.arpa` nos certificados
- ‚úÖ Certificados TLS criados com `local-ca`
- ‚úÖ Estrutura de ConfigMap e Secrets adequada
- ‚úÖ Probes de health configuradas
- ‚úÖ PodAntiAffinity correto (usa `app.kubernetes.io/name`)

---

## 3Ô∏è‚É£ MINIO - Problemas Identificados

### üî¥ ERRO CR√çTICO #1: Ingress com Classe Inv√°lida

**Arquivos**:
- `/home/k8s1/k8s/minio/21-minio-console-ingress.yaml` (linha 7)
- `/home/k8s1/k8s/minio/22-minio-s3-ingress.yaml` (linha 7)

**Problema**:
```yaml
annotations:
  kubernetes.io/ingress.class: public  # ‚ùå "public" n√£o existe no K3s!
```

**Impacto**:
- ‚õî **Ingress n√£o ser√° processado pelo Traefik**
- Console e S3 API n√£o estar√£o acess√≠veis
- MinIO ficar√° isolado internamente

**Corre√ß√£o Necess√°ria**:
```yaml
annotations:
  kubernetes.io/ingress.class: traefik  # ‚úÖ CORRETO
```

### üî¥ ERRO CR√çTICO #2: Annotation NGINX no S3 Ingress

**Arquivo**: `/home/k8s1/k8s/minio/22-minio-s3-ingress.yaml`
**Linha**: 9

**Problema**:
```yaml
annotations:
  nginx.ingress.kubernetes.io/force-ssl-redirect: "true"  # ‚ùå NGINX!
```

**Impacto**:
- Annotation ser√° ignorada pelo Traefik
- Redirecionamento HTTPS pode n√£o funcionar
- Configura√ß√£o inconsistente

**Corre√ß√£o Necess√°ria**:
- Remover annotation do NGINX
- Usar Middleware do Traefik para redirect HTTPS

### üî¥ ERRO CR√çTICO #3: Conflito de Configura√ß√µes de Ingress

**Arquivos**: 21, 22 (Ingress) + 32 (HTTPRoute) + 30, 31 (Gateway)

**Problema**:
- Tem **Ingress padr√£o** (arquivos 21, 22)
- Tem **HTTPRoute/Gateway API** (arquivos 30, 31, 32)
- Tem **m√∫ltiplas defini√ß√µes para os mesmos endpoints**

**Impacto**:
- üí• **CONFLITO**: Dois controladores tentando gerenciar as mesmas rotas
- Comportamento imprevis√≠vel
- Pode causar loops ou falhas de roteamento

**Corre√ß√£o Necess√°ria**:
- Escolher UMA abordagem: Ingress OU Gateway API
- **Recomendado**: Usar `IngressRoute` do Traefik (mais simples para K3s)

### ‚ö†Ô∏è ERRO M√âDIO: Inconsist√™ncia de Dom√≠nios

**Problema**:

| Arquivo | Configura√ß√£o | Dom√≠nio |
|---------|-------------|---------|
| StatefulSet linha 50 | `MINIO_SERVER_URL` | `minio.home.arpa` |
| StatefulSet linha 52 | `MINIO_BROWSER_REDIRECT_URL` | `console.minio.home.arpa` |
| Ingress 21 | Console | `console.minio.home.arpa` |
| Ingress 22 | S3 API | `minio-s3.home.arpa` ‚ùå |
| HTTPRoute | API | `minio.home.arpa` |
| HTTPRoute | Console | `console.minio.home.arpa` |

**Impacto**:
- Confus√£o entre `minio.home.arpa` e `minio-s3.home.arpa`
- Configura√ß√£o interna n√£o bate com Ingress externo

**Corre√ß√£o Necess√°ria**:
- Padronizar:
  - **S3 API**: `minio-s3.home.arpa` (conforme DNS-STANDARDS.md)
  - **Console**: `minio-console.home.arpa` (conforme DNS-STANDARDS.md)
- Atualizar vari√°veis de ambiente no StatefulSet

### üî¥ ERRO CR√çTICO #4: Dados N√£o Persistentes

**Arquivo**: `/home/k8s1/k8s/minio/20-statefulset.yaml`
**Linhas**: 81-82

**Problema**:
```yaml
volumes:
- name: data
  emptyDir: {}  # ‚ùå Armazenamento vol√°til!
```

**Impacto**:
- üí• **PERDA TOTAL DE DADOS ao reiniciar pod**
- Todos os objetos S3 ser√£o perdidos
- **INACEIT√ÅVEL PARA QUALQUER AMBIENTE**

**Corre√ß√£o Necess√°ria**:
```yaml
volumeClaimTemplates:
- metadata:
    name: data
  spec:
    accessModes: ["ReadWriteOnce"]
    storageClassName: local-path
    resources:
      requests:
        storage: 100Gi  # Ajustar conforme necessidade
```

### ‚úÖ Pontos Positivos do MinIO

- ‚úÖ DNS usa `.home.arpa`
- ‚úÖ Certificados com `local-ca`
- ‚úÖ Probes de health configuradas
- ‚úÖ Service Account configurado
- ‚úÖ Security Context adequado

---

## 4Ô∏è‚É£ ELK STACK

### ‚ö™ N√ÉO ENCONTRADO

N√£o foram encontrados arquivos de configura√ß√£o para ELK (Elasticsearch, Logstash, Kibana) no projeto.

**Diret√≥rios verificados**:
- `/home/k8s1/k8s/elk/` - n√£o existe
- `/home/k8s1/k8s/elasticsearch/` - n√£o existe
- `/home/k8s1/k8s/kibana/` - n√£o existe
- `/home/k8s1/k8s/logstash/` - n√£o existe

**A√ß√£o**: ‚è≠Ô∏è Nenhuma revis√£o necess√°ria

---

## üìã Plano de Corre√ß√£o Priorizado

### üö® PRIORIDADE CR√çTICA (Imediata)

1. **Redis**: Corrigir label no podAntiAffinity
2. **RabbitMQ**: Converter Ingress NGINX ‚Üí Traefik
3. **RabbitMQ**: Adicionar volumeClaimTemplates para persist√™ncia
4. **MinIO**: Corrigir ingressClass de "public" ‚Üí "traefik"
5. **MinIO**: Adicionar volumeClaimTemplates para persist√™ncia
6. **MinIO**: Resolver conflito Ingress vs Gateway API

### ‚ö†Ô∏è PRIORIDADE ALTA (Pr√≥ximas 24h)

7. **MinIO**: Remover annotation NGINX
8. **MinIO**: Padronizar dom√≠nios conforme DNS-STANDARDS.md
9. **RabbitMQ**: Considerar habilitar TLS para produ√ß√£o

### ‚ÑπÔ∏è PRIORIDADE M√âDIA (Pr√≥ximos 7 dias)

10. **Todos**: Adicionar monitoramento e alertas
11. **Todos**: Implementar backups automatizados
12. **Todos**: Documentar procedimentos operacionais

---

## üéØ Resumo de Impactos

### Impedimentos Totais (N√£o Funciona)

- ‚ùå RabbitMQ Management UI inacess√≠vel (Ingress NGINX)
- ‚ùå MinIO Console e S3 inacess√≠vel (Ingress classe "public")

### Riscos Cr√≠ticos (Perda de Dados)

- üí• RabbitMQ: Perda de mensagens/filas ao restart
- üí• MinIO: Perda de objetos S3 ao restart

### Degrada√ß√£o de Servi√ßo

- ‚ö†Ô∏è Redis: R√©plicas podem agendar no mesmo node (SPoF)
- ‚ö†Ô∏è MinIO: Redirecionamento HTTPS pode n√£o funcionar

---

## üìù Pr√≥ximos Passos

1. ‚úÖ Relat√≥rio gerado
2. ‚è≥ Aplicar corre√ß√µes cr√≠ticas
3. ‚è≥ Testar cada componente
4. ‚è≥ Validar persist√™ncia de dados
5. ‚è≥ Atualizar documenta√ß√£o

---

**Assinado**: SRE Principal
**Status**: AGUARDANDO APLICA√á√ÉO DE CORRE√á√ïES
