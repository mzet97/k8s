# Como Acessar o ELK Stack

## ‚úÖ ELK Stack Instalado com Sucesso

O **ELK Stack** (Elasticsearch + Logstash + Kibana + Filebeat) est√° dispon√≠vel em:

**Kibana**: https://kibana.home.arpa/
**Elasticsearch API**: https://elasticsearch.home.arpa/

## üîê Credenciais de Acesso

### Kibana
- **Usu√°rio**: `elastic`
- **Senha**: `Admin@123`

### Elasticsearch API
- **Usu√°rio**: `elastic`
- **Senha**: `Admin@123`

## üìã Informa√ß√µes da Instala√ß√£o

| Componente | URL/Endpoint | Porta |
|------------|--------------|-------|
| **Kibana** | https://kibana.home.arpa/ | 5601 |
| **Elasticsearch API** | https://elasticsearch.home.arpa/ | 9200 |
| **Elasticsearch Interno** | elasticsearch.elk.svc.cluster.local | 9200/9300 |
| **Logstash** | logstash.elk.svc.cluster.local | 5044 |
| **Filebeat** | DaemonSet (todos os nodes) | - |

### Detalhes T√©cnicos

| Item | Valor |
|------|-------|
| **Namespace** | elk |
| **Ingress IP** | 192.168.1.51 |
| **TLS** | ‚úÖ Sim (cert-manager local-ca) |
| **Elasticsearch R√©plicas** | 3 (cluster mode) |
| **Persist√™ncia (cada r√©plica)** | 50Gi |
| **Total de Storage** | ~150Gi |
| **StorageClass** | local-path (K3s) |
| **Vers√£o** | 7.17.16 (Elasticsearch, Kibana, Logstash, Filebeat) |

## üåê Configura√ß√£o DNS

### Se j√° configurou no roteador:
‚úÖ Voc√™ j√° apontou `*.home.arpa` para `192.168.1.51` no roteador
‚úÖ Pode acessar diretamente:
   - https://kibana.home.arpa/
   - https://elasticsearch.home.arpa/

### Se ainda n√£o configurou localmente:

**Linux/Mac**:
```bash
echo "192.168.1.51 kibana.home.arpa" | sudo tee -a /etc/hosts
echo "192.168.1.51 elasticsearch.home.arpa" | sudo tee -a /etc/hosts
```

**Windows** (como Administrador):
```powershell
Add-Content C:\Windows\System32\drivers\etc\hosts "192.168.1.51 kibana.home.arpa"
Add-Content C:\Windows\System32\drivers\etc\hosts "192.168.1.51 elasticsearch.home.arpa"
```

## üß™ Testar Acesso

### M√©todo 1: Browser (Kibana)
1. Abra o navegador
2. Acesse: https://kibana.home.arpa/
3. Aceite o certificado autoassinado (√© esperado)
4. Navegue sem login

### M√©todo 2: curl (Elasticsearch API)
```bash
# Testar sa√∫de do cluster
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cluster/health?pretty

# Listar √≠ndices
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cat/indices?v

# Ver informa√ß√µes do cluster
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cat/nodes?v
```

### M√©todo 3: Dentro do Cluster
```bash
# Entrar no pod do Elasticsearch
kubectl exec -it -n elk elasticsearch-0 -- sh

# Dentro do pod
curl http://localhost:9200/_cluster/health?pretty
curl http://localhost:9200/_cat/indices?v
```

## üìä Kibana - Visualiza√ß√£o e Dashboards

### üéØ O que voc√™ pode fazer no Kibana

‚úÖ **Discover**: Explorar logs e dados em tempo real
‚úÖ **Visualize**: Criar visualiza√ß√µes (gr√°ficos, tabelas, mapas)
‚úÖ **Dashboard**: Criar pain√©is com m√∫ltiplas visualiza√ß√µes
‚úÖ **Canvas**: Criar apresenta√ß√µes e infogr√°ficos
‚úÖ **Maps**: Visualizar dados geogr√°ficos
‚úÖ **Machine Learning**: Detectar anomalias (requer licen√ßa)
‚úÖ **Observability**: Monitorar APM, m√©tricas e logs
‚úÖ **Security**: An√°lise de seguran√ßa (requer licen√ßa)
‚úÖ **Stack Management**: Gerenciar √≠ndices, index patterns, saved objects

### Primeiros Passos no Kibana

#### 1. Criar Index Pattern

1. Acesse **Stack Management** ‚Üí **Index Patterns**
2. Clique em **Create index pattern**
3. Digite o padr√£o do √≠ndice (ex: `filebeat-*`)
4. Selecione **@timestamp** como Time field
5. Clique em **Create index pattern**

#### 2. Explorar Logs no Discover

1. Acesse **Discover** no menu lateral
2. Selecione o index pattern criado
3. Ajuste o intervalo de tempo (canto superior direito)
4. Use a barra de busca para filtrar logs:
   - `kubernetes.namespace: "default"`
   - `log.level: "error"`
   - `message: *exception*`

#### 3. Criar Visualiza√ß√£o

1. Acesse **Visualize** ‚Üí **Create visualization**
2. Escolha o tipo (Line, Bar, Pie, etc)
3. Selecione o index pattern
4. Configure m√©tricas e buckets
5. Clique em **Save**

#### 4. Criar Dashboard

1. Acesse **Dashboard** ‚Üí **Create dashboard**
2. Clique em **Add**
3. Selecione as visualiza√ß√µes criadas
4. Organize os pain√©is
5. Clique em **Save**

### Queries KQL (Kibana Query Language)

```
# Logs de um namespace espec√≠fico
kubernetes.namespace: "redis"

# Logs com erro
log.level: error OR log.level: ERROR

# Logs de um pod espec√≠fico
kubernetes.pod.name: "redis-master-0"

# Combinar condi√ß√µes
kubernetes.namespace: "elk" AND log.level: "error"

# Buscar por texto
message: "connection refused"

# Range de tempo (al√©m do seletor visual)
@timestamp >= "2025-12-11T00:00:00"

# Wildcards
kubernetes.pod.name: redis-*
```

## üîç Elasticsearch - API e Queries

### O que √© o Elasticsearch

Elasticsearch √© um motor de busca e analytics distribu√≠do, baseado em Lucene. Armazena dados em formato JSON e permite buscas complexas.

### Comandos √öteis da API

```bash
# Sa√∫de do cluster
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cluster/health?pretty

# Listar todos os √≠ndices
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cat/indices?v

# Ver nodes do cluster
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cat/nodes?v

# Estat√≠sticas de um √≠ndice
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/filebeat-*/_stats?pretty

# Buscar documentos
curl -k -u elastic:Admin@123 -X GET "https://elasticsearch.home.arpa/filebeat-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "kubernetes.namespace": "redis"
    }
  },
  "size": 10
}
'

# Criar um √≠ndice
curl -k -u elastic:Admin@123 -X PUT "https://elasticsearch.home.arpa/my-index"

# Indexar um documento
curl -k -u elastic:Admin@123 -X POST "https://elasticsearch.home.arpa/my-index/_doc" -H 'Content-Type: application/json' -d'
{
  "message": "Hello from API",
  "timestamp": "2025-12-11T12:00:00"
}
'

# Deletar um √≠ndice
curl -k -u elastic:Admin@123 -X DELETE "https://elasticsearch.home.arpa/my-index"
```

### Elasticsearch Query DSL

```json
{
  "query": {
    "bool": {
      "must": [
        { "match": { "kubernetes.namespace": "redis" } }
      ],
      "filter": [
        { "range": { "@timestamp": { "gte": "now-1h" } } }
      ],
      "must_not": [
        { "match": { "log.level": "debug" } }
      ]
    }
  },
  "aggs": {
    "logs_per_namespace": {
      "terms": { "field": "kubernetes.namespace.keyword" }
    }
  },
  "size": 100,
  "sort": [
    { "@timestamp": "desc" }
  ]
}
```

## üìù Logstash - Pipeline de Dados

### O que √© o Logstash

Logstash √© um pipeline de processamento de dados que ingere, transforma e envia dados para o Elasticsearch.

### Arquitetura

```
Input ‚Üí Filter ‚Üí Output
```

### Exemplo de Pipeline Logstash

```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  if [kubernetes][namespace] == "redis" {
    mutate {
      add_tag => ["redis"]
    }
  }

  if [log][level] == "error" {
    mutate {
      add_tag => ["error"]
    }
  }

  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:msg}" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
  }
}
```

### Ver Pipeline Configurado

```bash
kubectl get configmap logstash-pipeline -n elk -o yaml
```

## üìã Filebeat - Coletor de Logs

### O que √© o Filebeat

Filebeat √© um agente leve que coleta logs de arquivos e os envia para Logstash ou Elasticsearch.

### Como Funciona

1. Filebeat roda como **DaemonSet** (um pod por node)
2. Monta `/var/log/pods` dos hosts
3. L√™ logs de todos os containers
4. Envia para Logstash (porta 5044)
5. Logstash processa e envia para Elasticsearch
6. Kibana permite visualizar os logs

### Ver Logs do Filebeat

```bash
kubectl logs -n elk -l app.kubernetes.io/name=filebeat -f
```

### Configura√ß√£o do Filebeat

```yaml
filebeat.inputs:
- type: container
  paths:
    - /var/log/pods/*/*/*.log
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/pods/"

output.logstash:
  hosts: ["logstash:5044"]
```

## üîß Status dos Servi√ßos

### Verificar Pods
```bash
kubectl get pods -n elk
kubectl get statefulset -n elk
kubectl get daemonset -n elk
```

### Ver Logs
```bash
# Elasticsearch
kubectl logs -n elk elasticsearch-0 -f

# Kibana
kubectl logs -n elk -l app.kubernetes.io/name=kibana -f

# Logstash
kubectl logs -n elk -l app.kubernetes.io/name=logstash -f

# Filebeat
kubectl logs -n elk -l app.kubernetes.io/name=filebeat -f
```

### Verificar Sa√∫de do Cluster Elasticsearch
```bash
kubectl exec -n elk elasticsearch-0 -- curl http://localhost:9200/_cluster/health?pretty
```

### Verificar PVCs
```bash
kubectl get pvc -n elk
```

### Reiniciar Servi√ßos
```bash
# Elasticsearch
kubectl rollout restart statefulset/elasticsearch -n elk

# Kibana
kubectl rollout restart deployment/kibana -n elk

# Logstash
kubectl rollout restart deployment/logstash -n elk

# Filebeat
kubectl rollout restart daemonset/filebeat -n elk
```

## üö® Troubleshooting

### Kibana n√£o carrega
**Verificar se Elasticsearch est√° acess√≠vel**:
```bash
kubectl exec -n elk deployment/kibana -- curl http://elasticsearch:9200
```

### Elasticsearch cluster unhealthy
**Ver status**:
```bash
kubectl exec -n elk elasticsearch-0 -- curl http://localhost:9200/_cluster/health?pretty
```

**Poss√≠veis causas**:
- Pods ainda inicializando (aguarde alguns minutos)
- Problemas de recursos (CPU/mem√≥ria)
- Problemas de rede entre pods

### Logs n√£o aparecem no Kibana

**1. Verificar se Filebeat est√° coletando logs**:
```bash
kubectl logs -n elk -l app.kubernetes.io/name=filebeat --tail=50
```

**2. Verificar se Logstash est√° recebendo**:
```bash
kubectl logs -n elk -l app.kubernetes.io/name=logstash --tail=50
```

**3. Verificar √≠ndices no Elasticsearch**:
```bash
curl -k -u elastic:Admin@123 https://elasticsearch.home.arpa/_cat/indices?v
```

**4. Criar Index Pattern no Kibana**:
- Stack Management ‚Üí Index Patterns ‚Üí Create
- Use padr√£o: `filebeat-*` ou `logstash-*`

### Disco cheio
**Verificar uso de disco**:
```bash
kubectl exec -n elk elasticsearch-0 -- df -h /usr/share/elasticsearch/data
```

**Limpar √≠ndices antigos**:
```bash
# Deletar √≠ndices com mais de 30 dias
curl -k -u elastic:Admin@123 -X DELETE "https://elasticsearch.home.arpa/filebeat-*-$(date -d '30 days ago' +%Y.%m.%d)"
```

**Configurar ILM (Index Lifecycle Management)**:
- No Kibana: Stack Management ‚Üí Index Lifecycle Policies
- Configure reten√ß√£o autom√°tica de dados

### Elasticsearch OOM (Out of Memory)

**Ver uso de mem√≥ria**:
```bash
kubectl top pods -n elk
```

**Ajustar heap size** (editar ConfigMap):
```bash
kubectl edit configmap elasticsearch-config -n elk
```

Ajuste no arquivo `jvm.options`:
```
-Xms2g
-Xmx2g
```

Depois reinicie:
```bash
kubectl rollout restart statefulset/elasticsearch -n elk
```

## üìä Casos de Uso

### Monitorar Logs de Aplica√ß√£o

1. Aplica√ß√£o escreve logs em stdout/stderr
2. Filebeat coleta os logs
3. Envia para Logstash
4. Logstash processa e indexa no Elasticsearch
5. Visualize no Kibana ‚Üí Discover

### Alertas de Erro

1. Criar busca no Kibana para logs de erro
2. Stack Management ‚Üí Alerting and Actions
3. Criar regra de alerta baseada na busca
4. Configurar a√ß√£o (email, webhook, Slack)

### An√°lise de Performance

1. Indexar m√©tricas de performance (response time, throughput)
2. Criar visualiza√ß√µes de s√©ries temporais
3. Combinar em dashboard
4. Identificar gargalos e tend√™ncias

### An√°lise de Seguran√ßa

1. Indexar logs de auditoria e autentica√ß√£o
2. Buscar por padr√µes suspeitos (tentativas de login falhas, comandos suspeitos)
3. Criar alertas para atividades an√¥malas
4. Investigar incidentes via Discover

## üì± Acesso de Outros Dispositivos

### Mesmo Computador
‚úÖ Kibana: https://kibana.home.arpa/
‚úÖ Elasticsearch API: https://elasticsearch.home.arpa/

### Outro Computador na Mesma Rede
‚úÖ Com DNS do roteador configurado, acesse diretamente os URLs acima

### Aplica√ß√µes no Kubernetes
```bash
# Elasticsearch
http://elasticsearch.elk.svc.cluster.local:9200

# Logstash (Beats input)
logstash.elk.svc.cluster.local:5044
```

## üîí Seguran√ßa

### Autentica√ß√£o Habilitada

‚úÖ **X-Pack Security** est√° habilitado por padr√£o com as seguintes credenciais:
- **Usu√°rio**: `elastic`
- **Senha**: `Admin@123`

### Recuperar Credenciais

Se precisar recuperar as credenciais configuradas:
```bash
# Ver usu√°rio
kubectl get secret elastic-credentials -n elk -o jsonpath='{.data.username}' | base64 -d
echo

# Ver senha
kubectl get secret elastic-credentials -n elk -o jsonpath='{.data.password}' | base64 -d
echo
```

### Alterar Senha

Para alterar a senha do usu√°rio `elastic`:

```bash
# Op√ß√£o 1: Atualizar o secret
kubectl edit secret elastic-credentials -n elk
# Edite o campo 'password' com nova senha em base64

# Op√ß√£o 2: Deletar e recriar o secret
kubectl delete secret elastic-credentials -n elk
kubectl create secret generic elastic-credentials \
  --from-literal=username=elastic \
  --from-literal=password=NovaSenha@123 \
  --from-literal=ELASTIC_USERNAME=elastic \
  --from-literal=ELASTIC_PASSWORD=NovaSenha@123 \
  -n elk

# Reiniciar pods para aplicar nova senha
kubectl rollout restart statefulset/elasticsearch -n elk
kubectl rollout restart deployment/kibana -n elk
kubectl rollout restart deployment/logstash -n elk
```

## üìö Refer√™ncias

- **Elasticsearch**: https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html
- **Kibana**: https://www.elastic.co/guide/en/kibana/7.17/index.html
- **Logstash**: https://www.elastic.co/guide/en/logstash/7.17/index.html
- **Filebeat**: https://www.elastic.co/guide/en/beats/filebeat/7.17/index.html
- **KQL**: https://www.elastic.co/guide/en/kibana/7.17/kuery-query.html
- **Query DSL**: https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl.html

## üéâ Resumo

‚úÖ ELK Stack instalado com sucesso
‚úÖ Kibana: https://kibana.home.arpa/
‚úÖ Elasticsearch API: https://elasticsearch.home.arpa/
‚úÖ Elasticsearch: Cluster com 3 r√©plicas
‚úÖ Persist√™ncia: 3x 50Gi (150Gi total)
‚úÖ Filebeat: Coletando logs de todos os pods
‚úÖ Logstash: Processando e indexando logs
‚úÖ TLS configurado com cert-manager

**Analise seus logs com poder do ELK!** üîç
